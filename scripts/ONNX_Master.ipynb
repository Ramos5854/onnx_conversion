{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting Models via ONNX \n",
    "This script is designed to be the end-to-end master for converting models from one framework to another. The following frameworks are included:\n",
    "* Keras\n",
    "* Matlab (future)\n",
    "* PyTorch\n",
    "* Scikit-Learn\n",
    "* TensorFlow\n",
    "\n",
    "This scipt is to act as a function with the following parameters:\n",
    "**Input(s):**\n",
    "1. Model file name (provide absolute path if not within current dir)\n",
    "2. 'frameworkIn' format\n",
    "3. 'frameworkOut' format\n",
    "\n",
    "**Output(s):**\n",
    "1. Model in ONNX format\n",
    "2. Model in 'frameworkOut' format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User Inputs:\n",
    "frameworkIn = \"tensorflow\"    # {keras | matlab | onnx | pytorch | scikit-learn | tensorflow}\n",
    "frameworkOut = \"keras\"\n",
    "\n",
    "#pathIn = \"cifar_entire.pth\"\n",
    "\n",
    "netronView = False\n",
    "verboseMode= True           # display amplifying information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- 'ONNX_Master.ipynb' ---- \n",
      "\n",
      "Importing necessary packages... \n",
      "Required: {numpy | os | onnx | onnxruntime | pathlib | tensorflow}\n",
      "As needed: {keras | scikit-learn | tensorflow}\n",
      "\n",
      "Numpy version:\t\t 1.19.2 \n",
      "ONNX version:\t\t 1.7.0 \n",
      "ONNX Runtime version:\t 1.5.2 \n",
      "TensorFlow version:\t 2.2.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import pathlib\n",
    "import onnx\n",
    "import onnxruntime\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "# Lesser packages that we want to track versions of\n",
    "import numpy\n",
    "\n",
    "print(\"---- 'ONNX_Master.ipynb' ---- \\n\")\n",
    "\n",
    "print(\"Importing necessary packages... \\n\"\n",
    "      \"Required: {numpy | os | onnx | onnxruntime | pathlib | tensorflow}\\n\"\n",
    "      \"As needed: {keras | scikit-learn | tensorflow}\\n\")\n",
    "\n",
    "print(\"Numpy version:\\t\\t\", numpy.__version__, '\\n'\n",
    "      \"ONNX version:\\t\\t\", onnx.__version__, '\\n'\n",
    "      \"ONNX Runtime version:\\t\", onnxruntime.__version__, '\\n'\n",
    "      \"TensorFlow version:\\t\", tf.__version__, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug helper - assumes all models are local \n",
    "if frameworkIn == \"keras\":\n",
    "    pathIn = pathIn = \"mnist-model.h5\"\n",
    "elif frameworkIn == \"pytorch\":\n",
    "    pathIn = \"vgg16.pth\"\n",
    "elif frameworkIn == \"scikit-learn\":\n",
    "    pathIn = \"iris-model.pkl\"\n",
    "elif frameworkIn == \"tensorflow\":\n",
    "    pathIn = \"MNIST_tf.pb\"              # Not working\n",
    "    pathIn = \"mnist_tf.h5\"\n",
    "else:\n",
    "    print(\"ERROR: Invalid framework!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Defs for Generic Functions:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change file extension\n",
    "def ChangeExtension(fileIn, extOut):\n",
    "    ind = fileIn.find('.') + 1\n",
    "    base = fileIn[0:ind]\n",
    "    fileOut = fileIn[0:ind] + extOut\n",
    "    return fileOut, base\n",
    "\n",
    "def GetExtension(fileIn):\n",
    "    ind = fileIn.find('.') + 1\n",
    "    ext = fileIn[ind:len(fileIn)]\n",
    "    return ext\n",
    "\n",
    "# Print saved status\n",
    "def ModelSavedDialogue(modelSaved):\n",
    "    print(\"Dir: \", os.getcwd())\n",
    "    print(\"Model saved: \", modelSaved)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input File Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File path:  mnist_tf.h5 \n",
      "\n",
      "Model in:\t mnist_tf.h5 \n",
      "Model out:\t mnist_tf.onnx \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get import file\n",
    "pathIn = pathlib.Path(pathIn)\n",
    "modelIn = pathIn.name\n",
    "modelONNX, baseName = ChangeExtension(modelIn, 'onnx') \n",
    "\n",
    "print(\"File path: \", pathIn, \"\\n\\n\"\n",
    "      \"Model in:\\t\", modelIn, \"\\n\"\n",
    "      \"Model out:\\t\", modelONNX, \"\\n\")\n",
    "\n",
    "# Make sure modelIn is located within current working directory\n",
    "import shutil\n",
    "\n",
    "try:\n",
    "    shutil.copy(pathIn, os.getcwd())\n",
    "    print(\"'\", modelIn, \"' copied to current working directory...\")\n",
    "except shutil.SameFileError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Defs for Framework-In Conditions:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras\n",
    "if frameworkIn == \"keras\" or frameworkOut == \"keras\":\n",
    "    from tensorflow import keras\n",
    "    from tensorflow.keras import layers\n",
    "    import keras2onnx\n",
    "    print(\"keras2onnx Version: \"+ keras2onnx.__version__)\n",
    "\n",
    "def Keras_ONNX(modelIn, modelONNX):\n",
    "    # Load Keras model\n",
    "    modelKeras = tf.keras.models.load_model(modelIn)\n",
    "    print(\"Keras model loaded: \", modelIn)\n",
    "    if verboseMode: \n",
    "        print(\"Displaying Keras model summary...\\n\")\n",
    "        modelKeras.summary()\n",
    "        print(\"-\"*65, \"\\n\", \"-\"*65)\n",
    "    \n",
    "    # Convert to ONNX\n",
    "    debugMode = 0\n",
    "    if verboseMode: \n",
    "        print(\"Displaying ONNX model summary...\")\n",
    "        debugMode = 1\n",
    "    model = keras2onnx.convert_keras(modelKeras, baseName, debug_mode=debugMode)\n",
    "\n",
    "    # Save the model in ONNX format\n",
    "    keras2onnx.save_model(model, modelONNX)\n",
    "    \n",
    "    ModelSavedDialogue(modelONNX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matlab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch\n",
    "if frameworkIn == \"pytorch\" or frameworkOut == \"pytorch\":\n",
    "    import torch\n",
    "    import torchvision\n",
    "\n",
    "def PyTorch_ONNX(modelIn, modelONNX):\n",
    "    # Load PyTorch model {.pt | .pth}\n",
    "    model = torch.load(modelIn)\n",
    "    print(\"PyTorch model loaded: \", modelIn)\n",
    "    \n",
    "    if verboseMode:\n",
    "        from torchvision import models\n",
    "        #from torchsummary import summary\n",
    "        \n",
    "        print(\"Displaying shape...\\n\", model)\n",
    "        #summary(model, input_size=(1, 28, 28))\n",
    "    \n",
    "    # Convert to ONNX format   \n",
    "    torch.onnx.export(model, \n",
    "                      torch.randn(1, 3, 224, 224), \n",
    "                      modelONNX)\n",
    "    \n",
    "    ModelSavedDialogue(modelONNX)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scikit-Learn\n",
    "if frameworkIn == \"scikit-learn\" or frameworkOut == \"scikit-learn\":\n",
    "    import pandas\n",
    "    import pickle\n",
    "    from skl2onnx import convert_sklearn\n",
    "    from skl2onnx.common.data_types import FloatTensorType\n",
    "    \n",
    "def ScikitLearn_ONNX(modelIn, modelONNX):\n",
    "    # Load SciKit-Learn Model (as .pkl)\n",
    "    with open(modelIn, 'rb') as file:\n",
    "        model = pickle.load(file)\n",
    "        \n",
    "    print(\"Scikit_Learn model loaded: \", modelIn)\n",
    "    \n",
    "    # Convert to ONNX\n",
    "    initial_type = [('float_input', FloatTensorType([None, 4]))]\n",
    "    onnx = convert_sklearn(model, initial_types=initial_type)\n",
    "    with open(modelONNX, \"wb\") as file:\n",
    "        file.write(onnx.SerializeToString())\n",
    "    \n",
    "    ModelSavedDialogue(modelONNX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF2ONNX Version:  1.7.2\n"
     ]
    }
   ],
   "source": [
    "# TensorFlow\n",
    "if frameworkIn == \"tensorflow\" or frameworkOut == \"tensorflow\":\n",
    "#    import numpy # should already be imported\n",
    "    import tf2onnx\n",
    "    print(\"TF2ONNX Version: \", tf2onnx.__version__)\n",
    "    \n",
    "def TensorFlow_ONNX(modelIn, modelONNX):\n",
    "    print(\"TensorFlow model loaded: \", modelIn)\n",
    "    \n",
    "    ext = GetExtension(modelIn)\n",
    "    _, base = ChangeExtension(modelIn, \"\")\n",
    "    modelDescription = base.join(\" model\")\n",
    "    \n",
    "    # Load TensorFlow model via one of two methods\n",
    "    if ext == \"pb\":\n",
    "    # Reference: https://docs.unity3d.com/Packages/com.unity.barracuda@1.0/manual/Exporting.html\n",
    "        graph_def = tf.compat.v1.GraphDef()\n",
    "        with open(modelIn, 'rb') as f:\n",
    "            graph_def.ParseFromString(f.read())\n",
    "        \n",
    "        with tf.Graph().as_default() as graph:\n",
    "            tf.import_graph_def(graph_def, name='')\n",
    "        \n",
    "        #inputs[:] = [i + \":0\" for i in inputs]\n",
    "        #outputs[:] = [o + \":0\" for o in outputs]\n",
    "    \n",
    "        with tf.compat.v1.Session() as sess:\n",
    "            g = tf2onnx.tfonnx.process_tf_graph(sess.graph, \n",
    "                                                input_names=inputs, \n",
    "                                                output_names=outputs)\n",
    "            model_proto = g.make_model(modelDescription)\n",
    "            checker = onnx.checker.check_model(model_proto)\n",
    "\n",
    "            tf2onnx.utils.save_onnx_model(modelONNX, \n",
    "                                          feed_dict={}, \n",
    "                                          model_proto=model_proto)\n",
    "    elif ext == \"h5\":\n",
    "        tf.keras.models.load_model(modelIn) # expecting h5 format\n",
    "    \n",
    "        # Convert to ONNX\n",
    "        with tf.compat.v1.Session() as sess:\n",
    "            x = tf.compat.v1.placeholder(tf.float32, [2, 3], name=\"input\")\n",
    "            x_ = tf.compat.v1.add(x, x)\n",
    "            _ = tf.compat.v1.identity(x_, name=\"output\")\n",
    "\n",
    "            # Convert Protobuf format and map to ONNX model\n",
    "            onnx_graph = tf2onnx.tfonnx.process_tf_graph(sess.graph, \n",
    "                                                         input_names=[\"input:0\"], \n",
    "                                                         output_names=[\"output:0\"])\n",
    "            model_proto = onnx_graph.make_model(modelDescription)\n",
    "            with open(modelONNX, \"wb\") as f:\n",
    "                f.write(model_proto.SerializeToString())\n",
    "    \n",
    "    ModelSavedDialogue(modelONNX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting model:  tensorflow  to ONNX...\n",
      "\n",
      "---- Conversion_To_ONNX.ipynb ----\n",
      "Base packages imported:\t onnx | onnxruntime | os\n",
      "Conversion_To_ONNX.ipynb running...\n",
      "tf2onnx:\t 1.7.2 \n",
      "\n",
      "Packages imported:\t {tf2onnx} \n",
      "\n",
      "TensorFlow model loaded:  mnist_tf.h5\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'tf2onnx' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-af2afea0b010>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# Run conversion script from external notebook\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mmodelONNX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mConvert_to_ONNX\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodelIn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodelONNX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframeworkIn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-8-96ec6d13d358>\u001b[0m in \u001b[0;36mConvert_to_ONNX\u001b[1;34m(modelIn, modelONNX, frameworkIn)\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mScikitLearn_ONNX\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodelIn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodelONNX\u001b[0m\u001b[1;33m)\u001b[0m     \u001b[1;31m# Tested\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mframeworkIn\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"tensorflow\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0mTensorFlow_ONNX\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodelIn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodelONNX\u001b[0m\u001b[1;33m)\u001b[0m      \u001b[1;31m# Tested (h5)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Invalid framework chosen.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-ff54f91b9ed9>\u001b[0m in \u001b[0;36mTensorFlow_ONNX\u001b[1;34m(modelIn, modelONNX)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m             \u001b[1;31m# Convert Protobuf format and map to ONNX model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m             onnx_graph = tf2onnx.tfonnx.process_tf_graph(sess.graph, \n\u001b[0m\u001b[0;32m     43\u001b[0m                                                          \u001b[0minput_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"input:0\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m                                                          output_names=[\"output:0\"])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tf2onnx' is not defined"
     ]
    }
   ],
   "source": [
    "# Converting Class (frameworkIn -> ONNX)\n",
    "print(\"Converting model: \", frameworkIn, \" to ONNX...\\n\")\n",
    "\n",
    "%run Conversion_To_ONNX.ipynb\n",
    "print(\"Conversion_To_ONNX.ipynb running...\")\n",
    "\n",
    "# Run conversion script from external notebook\n",
    "modelONNX = Convert_to_ONNX(modelIn, modelONNX, frameworkIn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting model:  tensorflow  to ONNX...\n",
      "TensorFlow model loaded:  mnist_tf.h5\n",
      "Dir:  C:\\Users\\aaram\\Desktop\\Code 717\\Machine Learning\\ML Projects\\ONNX\n",
      "Model saved:  mnist_tf.onnx\n"
     ]
    }
   ],
   "source": [
    "# Converting Class (frameworkIn -> ONNX)\n",
    "print(\"Converting model: \", frameworkIn, \" to ONNX...\\n\")\n",
    "\n",
    "if frameworkIn == \"keras\":\n",
    "    Keras_ONNX(modelIn, modelONNX)           # Tested\n",
    "elif frameworkIn == \"pytorch\":\n",
    "    PyTorch_ONNX(modelIn, modelONNX)         # Tested \n",
    "elif frameworkIn == \"onnx\":\n",
    "    print(\"Model already in ONNX format!\")\n",
    "elif frameworkIn == \"scikit-learn\":\n",
    "    ScikitLearn_ONNX(modelIn, modelONNX)     # Tested\n",
    "elif frameworkIn == \"tensorflow\":\n",
    "    TensorFlow_ONNX(modelIn, modelONNX)      # Tested (h5)\n",
    "else:\n",
    "    print(\"Invalid framework chosen.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Verify ONNX Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnist_tf.onnx  has been loaded and checked!\n"
     ]
    }
   ],
   "source": [
    "# Load ONNX Model\n",
    "onnxIn = onnx.load(modelONNX)\n",
    "\n",
    "# Check that IR is well formed\n",
    "onnx.checker.check_model(onnxIn)\n",
    "print(modelONNX, \" has been loaded and checked!\")\n",
    "\n",
    "# Print human readable representation of graph\n",
    "#onnx.helper.printable_graph(modelONNX.graph)\n",
    "\n",
    "# Use Netron to view model\n",
    "if netronView:\n",
    "    print(\"Loading Netron in separate tab...\")\n",
    "    netron.start(onnxIn, port=8081)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Defs for Converting ONNX to frameworkOut**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras [Output]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if frameworkOut == \"pytorch\":\n",
    "    \n",
    "def ONNX_PyTorch(onnxIn, modelOut):\n",
    "    print(\"Currently PyTorch does not support conversion from ONNX: \", \"\\n\"\n",
    "          \"https://stackoverflow.com/questions/58833870/cant-we-run-an-onnx-model-imported-to-pytorch#:~:text=PyTorch%20doesn't%20currently%20support,to%20and%20from%20various%20frameworks.\")\n",
    "          \n",
    "    # Convert to PyTorch\n",
    "    #torch.save(model, modelOut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if frameworkOut == \"tensorflow\":\n",
    "    from onnx_tf.backend import prepare\n",
    "\n",
    "def ONNX_TensorFlow(onnxIn):\n",
    "    # ONNX model already loaded and verified above [onnxIn]\n",
    "    \n",
    "    # Import ONNX model to TensorFlow\n",
    "    tf_rep = prepare(onnxIn)\n",
    "    tf_rep.export_graph(modelOut)\n",
    "    \n",
    "    modelLoad = modelBase + \"\\saved_model.pb\"\n",
    "    ModelSavedDialogue(modelLoad)\n",
    "    \n",
    "    # Display results\n",
    "    print(\"Displaying model...\", \"\\n\"\n",
    "          \"Input nodes: \", tf_rep.inputs, \"\\n\"\n",
    "          \"Model output nodes: \", tf_rep.outputs, \"\\n\\n\"\n",
    "          \"All Model nodes: \", tf_rep.tensor_dict)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to FrameworkOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONNX file already created!\n",
      "Conversion complete!\n",
      "-----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Converting Class (ONNX -> frameworkOut)\n",
    "if frameworkOut == \"keras\": \n",
    "    modelOut = ChangeExtension(onnxIn, \"h5\")       # \n",
    "    ONNX_keras(onnxIn, modelOut)\n",
    "elif frameworkOut == \"onnx\":                     \n",
    "    print(\"ONNX file already created!\")\n",
    "elif frameworkOut == \"pytorch\": \n",
    "    modelOut = ChangeExtension(onnxIn, \"pt\")       #\n",
    "    ONNX_PyTorch(onnxIn, modelOut)\n",
    "elif frameworkOut == \"scikit-learn\": \n",
    "    modelOut = ChangeExtension(onnxIn, \"pb\")       #\n",
    "    ONNX_ScikitLearn(onnxIn, modelOut), \n",
    "elif frameworkOut == \"tensorflow\": \n",
    "    modelOut = ChangeExtension(onnxIn, \"tf\")       #\n",
    "    ONNX_TensorFlow(onnxIn, modelOut),\n",
    "    \n",
    "print(\"Conversion complete!\")\n",
    "print(\"-\"*65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
