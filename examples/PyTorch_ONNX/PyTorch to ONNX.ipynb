{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch to ONNX\n",
    "\n",
    "The following script will demonstrate the process of exporting a pretrained AlexNet. It runs a single round of inference and then saves the resulting traced model to alexnet.onnx\n",
    "1. Load pretrained AlexNet from torchvision.models\n",
    "2. Define Input/Output names for model\n",
    "3. Convert model to ONNX via built-in methods\n",
    "4. Run inferencing via ONNX Runtime\n",
    "\n",
    "**Tested Package Versions:**\n",
    "* PyTorch:     1.7.0\n",
    "* Torchvision: 0.8.1\n",
    "\n",
    "**Reference:**\n",
    "https://pytorch.org/docs/stable/onnx.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User Input\n",
    "modelOut = \"alexnet.onnx\"\n",
    "verboseMode = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----PyTorch to ONNX.ipynb----\n",
      "\n",
      "Torch Version:\t\t 1.7.0\n",
      "TorchVision Version:\t 0.8.1\n"
     ]
    }
   ],
   "source": [
    "# Setup\n",
    "print(\"----PyTorch to ONNX.ipynb----\\n\")\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "print(\"Torch Version:\\t\\t\", torch.__version__)\n",
    "print(\"TorchVision Version:\\t\", torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing AlexNet...\n",
      "'AlexNet' model successfully imported!\n"
     ]
    }
   ],
   "source": [
    "# Load AlexNet Model\n",
    "print(\"Importing AlexNet...\")\n",
    "\n",
    "# Note, this is being loaded for CPU usage\n",
    "dummy_input = torch.randn(10, 3, 224, 224, device='cpu')\n",
    "model = torchvision.models.alexnet(pretrained=True)\n",
    "print(\"'AlexNet' model successfully imported!\\n\")\n",
    "\n",
    "# The download took approximately 1 min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup Model and Export\n",
    "\n",
    "Providing input and output names sets the display names for values within the model's graph. Setting these does not change the semantics of the graph; it is only for readability.\n",
    "\n",
    "The inputs to the network consist of the flat list of inputs (i.e. the values you would pass to the forward() method) followed by the flat list of parameters. You can partially specify names, i.e. provide a list here shorter than the number of inputs to the model, and we will only set that subset of names, starting from the beginning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defining input/output names...\n",
      "\n",
      "graph(%actual_input_1 : Float(10:150528, 3:50176, 224:224, 224:1, requires_grad=0, device=cpu),\n",
      "      %learned_0 : Float(64:363, 3:121, 11:11, 11:1, requires_grad=1, device=cpu),\n",
      "      %learned_1 : Float(64:1, requires_grad=1, device=cpu),\n",
      "      %learned_2 : Float(192:1600, 64:25, 5:5, 5:1, requires_grad=1, device=cpu),\n",
      "      %learned_3 : Float(192:1, requires_grad=1, device=cpu),\n",
      "      %learned_4 : Float(384:1728, 192:9, 3:3, 3:1, requires_grad=1, device=cpu),\n",
      "      %learned_5 : Float(384:1, requires_grad=1, device=cpu),\n",
      "      %learned_6 : Float(256:3456, 384:9, 3:3, 3:1, requires_grad=1, device=cpu),\n",
      "      %learned_7 : Float(256:1, requires_grad=1, device=cpu),\n",
      "      %learned_8 : Float(256:2304, 256:9, 3:3, 3:1, requires_grad=1, device=cpu),\n",
      "      %learned_9 : Float(256:1, requires_grad=1, device=cpu),\n",
      "      %learned_10 : Float(4096:9216, 9216:1, requires_grad=1, device=cpu),\n",
      "      %learned_11 : Float(4096:1, requires_grad=1, device=cpu),\n",
      "      %learned_12 : Float(4096:4096, 4096:1, requires_grad=1, device=cpu),\n",
      "      %learned_13 : Float(4096:1, requires_grad=1, device=cpu),\n",
      "      %learned_14 : Float(1000:4096, 4096:1, requires_grad=1, device=cpu),\n",
      "      %learned_15 : Float(1000:1, requires_grad=1, device=cpu)):\n",
      "  %17 : Float(10:193600, 64:3025, 55:55, 55:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[11, 11], pads=[2, 2, 2, 2], strides=[4, 4]](%actual_input_1, %learned_0, %learned_1) # E:\\Desktop\\Code_717\\miniconda3\\envs\\onnx_master\\lib\\site-packages\\torch\\nn\\modules\\conv.py:420:0\n",
      "  %18 : Float(10:193600, 64:3025, 55:55, 55:1, requires_grad=1, device=cpu) = onnx::Relu(%17) # E:\\Desktop\\Code_717\\miniconda3\\envs\\onnx_master\\lib\\site-packages\\torch\\nn\\functional.py:1134:0\n",
      "  %19 : Float(10:46656, 64:729, 27:27, 27:1, requires_grad=1, device=cpu) = onnx::MaxPool[kernel_shape=[3, 3], pads=[0, 0, 0, 0], strides=[2, 2]](%18) # E:\\Desktop\\Code_717\\miniconda3\\envs\\onnx_master\\lib\\site-packages\\torch\\nn\\functional.py:586:0\n",
      "  %20 : Float(10:139968, 192:729, 27:27, 27:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[5, 5], pads=[2, 2, 2, 2], strides=[1, 1]](%19, %learned_2, %learned_3) # E:\\Desktop\\Code_717\\miniconda3\\envs\\onnx_master\\lib\\site-packages\\torch\\nn\\modules\\conv.py:420:0\n",
      "  %21 : Float(10:139968, 192:729, 27:27, 27:1, requires_grad=1, device=cpu) = onnx::Relu(%20) # E:\\Desktop\\Code_717\\miniconda3\\envs\\onnx_master\\lib\\site-packages\\torch\\nn\\functional.py:1134:0\n",
      "  %22 : Float(10:32448, 192:169, 13:13, 13:1, requires_grad=1, device=cpu) = onnx::MaxPool[kernel_shape=[3, 3], pads=[0, 0, 0, 0], strides=[2, 2]](%21) # E:\\Desktop\\Code_717\\miniconda3\\envs\\onnx_master\\lib\\site-packages\\torch\\nn\\functional.py:586:0\n",
      "  %23 : Float(10:64896, 384:169, 13:13, 13:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%22, %learned_4, %learned_5) # E:\\Desktop\\Code_717\\miniconda3\\envs\\onnx_master\\lib\\site-packages\\torch\\nn\\modules\\conv.py:420:0\n",
      "  %24 : Float(10:64896, 384:169, 13:13, 13:1, requires_grad=1, device=cpu) = onnx::Relu(%23) # E:\\Desktop\\Code_717\\miniconda3\\envs\\onnx_master\\lib\\site-packages\\torch\\nn\\functional.py:1134:0\n",
      "  %25 : Float(10:43264, 256:169, 13:13, 13:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%24, %learned_6, %learned_7) # E:\\Desktop\\Code_717\\miniconda3\\envs\\onnx_master\\lib\\site-packages\\torch\\nn\\modules\\conv.py:420:0\n",
      "  %26 : Float(10:43264, 256:169, 13:13, 13:1, requires_grad=1, device=cpu) = onnx::Relu(%25) # E:\\Desktop\\Code_717\\miniconda3\\envs\\onnx_master\\lib\\site-packages\\torch\\nn\\functional.py:1134:0\n",
      "  %27 : Float(10:43264, 256:169, 13:13, 13:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%26, %learned_8, %learned_9) # E:\\Desktop\\Code_717\\miniconda3\\envs\\onnx_master\\lib\\site-packages\\torch\\nn\\modules\\conv.py:420:0\n",
      "  %28 : Float(10:43264, 256:169, 13:13, 13:1, requires_grad=1, device=cpu) = onnx::Relu(%27) # E:\\Desktop\\Code_717\\miniconda3\\envs\\onnx_master\\lib\\site-packages\\torch\\nn\\functional.py:1134:0\n",
      "  %29 : Float(10:9216, 256:36, 6:6, 6:1, requires_grad=1, device=cpu) = onnx::MaxPool[kernel_shape=[3, 3], pads=[0, 0, 0, 0], strides=[2, 2]](%28) # E:\\Desktop\\Code_717\\miniconda3\\envs\\onnx_master\\lib\\site-packages\\torch\\nn\\functional.py:586:0\n",
      "  %30 : Float(10:9216, 256:36, 6:6, 6:1, requires_grad=1, device=cpu) = onnx::AveragePool[kernel_shape=[1, 1], strides=[1, 1]](%29) # E:\\Desktop\\Code_717\\miniconda3\\envs\\onnx_master\\lib\\site-packages\\torch\\nn\\functional.py:936:0\n",
      "  %31 : Float(10:9216, 9216:1, requires_grad=1, device=cpu) = onnx::Flatten[axis=1](%30) # E:\\Desktop\\Code_717\\miniconda3\\envs\\onnx_master\\lib\\site-packages\\torch\\nn\\functional.py:983:0\n",
      "  %32 : Float(10:4096, 4096:1, requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%31, %learned_10, %learned_11) # E:\\Desktop\\Code_717\\miniconda3\\envs\\onnx_master\\lib\\site-packages\\torch\\nn\\functional.py:1690:0\n",
      "  %33 : Float(10:4096, 4096:1, requires_grad=1, device=cpu) = onnx::Relu(%32) # E:\\Desktop\\Code_717\\miniconda3\\envs\\onnx_master\\lib\\site-packages\\torch\\nn\\functional.py:983:0\n",
      "  %34 : Float(10:4096, 4096:1, requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%33, %learned_12, %learned_13) # E:\\Desktop\\Code_717\\miniconda3\\envs\\onnx_master\\lib\\site-packages\\torch\\nn\\functional.py:1690:0\n",
      "  %35 : Float(10:4096, 4096:1, requires_grad=1, device=cpu) = onnx::Relu(%34) # E:\\Desktop\\Code_717\\miniconda3\\envs\\onnx_master\\lib\\site-packages\\torch\\nn\\functional.py:1134:0\n",
      "  %output1 : Float(10:1000, 1000:1, requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%35, %learned_14, %learned_15) # E:\\Desktop\\Code_717\\miniconda3\\envs\\onnx_master\\lib\\site-packages\\torch\\nn\\functional.py:1690:0\n",
      "  return (%output1)\n",
      "\n",
      "\n",
      "Model exported:  alexnet.onnx\n"
     ]
    }
   ],
   "source": [
    "# Setup\n",
    "print(\"Defining input/output names...\\n\")\n",
    "input_names = [ \"actual_input_1\" ] + [ \"learned_%d\" % i for i in range(16) ]\n",
    "output_names = [ \"output1\" ]\n",
    "\n",
    "# Export \n",
    "torch.onnx.export(model, dummy_input, modelOut, verbose=verboseMode, input_names=input_names, output_names=output_names)\n",
    "print(\"\\nModel exported: \", modelOut, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:**\n",
    "This essentially created a binary protobuf file named 'alexnet.onnx' which contains both the network structure and parameters of the model exported. \n",
    "\n",
    "The argument verbose=True causes the exporter to print out a human-readable representaton of the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "' alexnet.onnx ' loaded successfully!\n",
      "\n",
      "Printing model graph...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load Model From ONNX\n",
    "import onnx\n",
    "\n",
    "model = onnx.load(\"alexnet.onnx\")\n",
    "print(\"'\", modelOut, \"' loaded successfully!\\n\")\n",
    "\n",
    "# Check that IR is well formed\n",
    "onnx.checker.check_model(model)\n",
    "\n",
    "# Print human readable representation of graph\n",
    "if verboseMode:\n",
    "    print(\"Printing model graph...\\n\")\n",
    "    onnx.helper.printable_graph(model.graph)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perform Inference with ONNX Runtime\n",
    "\n",
    "**Note: We must designate the data type of the output such that it will match the input datatpye. Float32 is a fairly common and precise datatype.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.32908696 -1.4375494  -1.171913   ... -0.97837996 -1.1469944\n",
      "   1.0900817 ]\n",
      " [-0.10875634 -1.1032635  -1.051388   ... -1.3563275  -0.9471036\n",
      "   0.98995644]\n",
      " [ 0.13966255 -1.3960574  -1.5738554  ... -1.308495   -0.82824004\n",
      "   0.8751602 ]\n",
      " ...\n",
      " [-0.1709329  -1.445117   -1.2844281  ... -1.512876   -1.0836242\n",
      "   1.3018279 ]\n",
      " [-0.084096   -1.3492982  -1.3600118  ... -1.125779   -0.8830015\n",
      "   1.2827814 ]\n",
      " [ 0.10905553 -1.2827294  -1.3019022  ... -1.3264313  -0.74955183\n",
      "   0.54748124]]\n"
     ]
    }
   ],
   "source": [
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "\n",
    "ort.session = ort.InferenceSession('alexnet.onnx')\n",
    "\n",
    "outputs = ort.session.run(None, {'actual_input_1': np.random.randn(10, 3, 224, 224).astype(np.float32)})\n",
    "\n",
    "print(outputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
