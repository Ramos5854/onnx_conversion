{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert ONNX Model to TensorFlow\n",
    "\n",
    "This tutorial loads the MNIST ONNX model generated from *PyTorch to TF.ipynb* and saves within the TensorFlow framework. \n",
    "\n",
    "The original tutorial utilizes the *super_resolution.onnx* model and performs processing on the image by resizing, eventually saving the resized image. \n",
    "\n",
    "Reference: \n",
    "https://github.com/onnx/tutorials/blob/master/tutorials/OnnxTensorflowImport.ipynb\n",
    "\n",
    "**Workflow**\n",
    "\n",
    "0. Ignore warning messages\n",
    "1. Load ONNX file, mnist-pyt.onnx\n",
    "2. Import ONNX model to TensorFlow\n",
    "\n",
    "Note: tf_rep is a python class containing four members: graph, inputs, outputs, and tensor_dict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: mnist-pyt.pb\\assets\n",
      "Model folder created:  mnist-pyt.pb\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "import warnings\n",
    "from onnx_tf.backend import prepare\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "modelIn = \"mnist-pyt.onnx\"\n",
    "modelOut = \"mnist-pyt.pb\"\n",
    "\n",
    "onnx_model = onnx.load(modelIn)\n",
    "tf_rep = prepare(onnx_model)\n",
    "tf_rep.export_graph(modelOut)\n",
    "\n",
    "print(\"Model folder created: \", modelOut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving 'mnist-pyt.onnx' at http://localhost:8081\n",
      "\n",
      "Stopping http://localhost:8081\n",
      "Serving 'mnist-pyt.pb\\saved_model.pb' at http://localhost:8081\n"
     ]
    }
   ],
   "source": [
    "# Use Netron to view model\n",
    "import netron\n",
    "\n",
    "modelLoad = 'mnist-pyt.pb\\saved_model.pb'\n",
    "\n",
    "# ONNX Model\n",
    "netron.start(modelIn, port=8081)\n",
    "\n",
    "# Tensorflow Model\n",
    "#netron.start(modelLoad, port=8082)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model input nodes:  ['input.1']\n",
      "Model output nodes:  ['20']\n",
      "\n",
      " All Model nodes:  None\n"
     ]
    }
   ],
   "source": [
    "# Print tf_rep nodes:\n",
    "print(\"Model input nodes: \", tf_rep.inputs)\n",
    "print(\"Model output nodes: \", tf_rep.outputs)\n",
    "\n",
    "print(\"\\n All Model nodes: \", tf_rep.tensor_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Input for Inference\n",
    "\n",
    "Warning: This code is intended to run using TensorFlow 2.2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorboard as tb\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import logging, os\n",
    "\n",
    "logging.disable(logging.WARNING)\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    " \n",
    "INPUT_TENSOR_NAME = 'input.1:0'\n",
    "OUTPUT_TENSOR_NAME = 'add_4:0'\n",
    "IMAGE_PATH=\"img_1.jpg\"\n",
    "PB_PATH=modelOut\n",
    " \n",
    "img = cv2.imread(IMAGE_PATH)\n",
    "img = np.dot(img[...,:3], [0.299, 0.587, 0.114])\n",
    "img = cv2.resize(img, dsize=(28, 28), interpolation=cv2.INTER_AREA)\n",
    "img.resize((1, 1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABwklEQVR4nL2Su2sUYRTFf983385zsyYmiq9CIhbBB1ooiBCIlSBBG/8Kia1NwEqwsrS0SyMIIipaig9UsPIBBhTxAUpwE3dmmc3MzhyL3SAbrT3t5Xfvuede2JDxwFkSaBkmGVUTAkyMteN43mgtCAkhhEkw23CbUAMGgATiUXSMLfGu6Yn5e3f2baYArtdFmfb7OuTTIBqdefqV2qnqsvfi2Ym/3C7rl9aLspA6n47S3DBiPWsNc19VZ5emZy4W6i1ODSoGDdbMZmdid+sjPD+YYJoZgDUDGqwjIfA5k0l/DBvrOUcLiLAwLVVxDODAGKMKL2Os7lL7/hwqG9WQM2Y4nIafwMSDXOkYAM5TDVhLP+kePpDfJpwVH9IoB5ypwfihO+fOBkfG9Vj7q+j1qSAftHWwd+Fhro4yqVNqTVpeHKZngctakfJvbzqF1FO1rvTmMKGEqJJ+vDzPsSdtfWlfW3ikNd0FwGe76aa13q98fpuVWp2Hqfv5aroRglsq1VWnKvT0wkm2Wp/jujE4/47v+Huu7G4HP6++C/sUNEqjVlYDxLRo0sDgEwAhMQ2IB01bONgJEUQkGLAQ/ONT/o9+AwaCrAyXKnAbAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x22E65231400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "\n",
    "image = \"img_1.jpg\"\n",
    "\n",
    "img = Image.open(image).resize((28, 28))\n",
    "display(img) # show the image\n",
    "img_ycbcr = img.convert(\"YCbCr\")\n",
    "img_y, img_cb, img_cr = img_ycbcr.split()\n",
    "model_y = np.asarray(img_y, dtype=np.float32)[np.newaxis, np.newaxis, :, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Model withing TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 10)\n"
     ]
    }
   ],
   "source": [
    "# Run model and print shape\n",
    "mod_image = tf_rep.run(model_y)._0\n",
    "print(mod_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
