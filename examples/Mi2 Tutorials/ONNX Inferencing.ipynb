{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ONNX Inferencing\n",
    "\n",
    "### Writing  Inference Code for Prediction\n",
    "\n",
    "This script is intended to perform inference on a pre-trained MNIST model.\n",
    "\n",
    "Reference: \n",
    "https://thenewstack.io/tutorial-using-a-pre-trained-onnx-model-for-inferencing/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import onnx\n",
    "import onnxruntime\n",
    "from onnx import numpy_helper\n",
    "\n",
    "from pathlib import Path, PureWindowsPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image found! \n",
      "\n",
      "Current Dir:  C:\\Users\\aaram\\Desktop\\Code 717\\Machine Learning\\ML Projects\\ONNX\\Mi2 Tutorials\n",
      "\n",
      "Model:  mnist-8.onnx\n",
      "\n",
      "Image Loc: C:\\Users\\aaram\\Desktop\\Code 717\\Machine Learning\\Databases\\mnist_db\\img_1.jpg\n"
     ]
    }
   ],
   "source": [
    "# Initialize variables to store model path and model files\n",
    "cur_dir = os.getcwd()\n",
    "model_dir = Path(os.getcwd())\n",
    "model = \"mnist-8.onnx\"\n",
    "\n",
    "img_dir = PureWindowsPath(\"C:\\\\Users\\\\aaram\\\\Desktop\\\\Code 717\\\\Machine Learning\\\\Databases\\\\mnist_db\")\n",
    "img_name = \"img_1.jpg\"\n",
    "img_path = Path(img_dir) / img_name\n",
    "\n",
    "if not img_path.exists():\n",
    "    print(\"ERROR: Image file does not exist\")\n",
    "else:\n",
    "    print(\"Image found! \\n\")\n",
    "\n",
    "print(\"Current Dir: \", cur_dir)\n",
    "print(\"\")\n",
    "print(\"Model: \", model)\n",
    "print(\"\")\n",
    "print(\"Image Loc:\", img_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Image and Preprocess \n",
    "\n",
    "The following converts the image to grayscale and resizes to an 28x28 array. The array is used as an input to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Shape  (28, 28)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load and Preprocess the Image using OpenCV\n",
    "# Note: imread is not reading in the absolute path for some reason\n",
    "\n",
    "# Use cv2 to read an image from working directory (in grayscale)\n",
    "img = cv2.imread(img_name, 0)\n",
    "# Show image\n",
    "from matplotlib import pyplot as plt\n",
    "print(\"Image Shape \", img.shape) # imshow requires 2D array for plotting\n",
    "plt.imshow(img, 'gray')\n",
    "plt.title(img_name)\n",
    "plt.xticks([]), plt.yticks([])  # to hide tick values on X and Y axis\n",
    "plt.show()\n",
    "\n",
    "img = np.dot(img[...,:3], [0.299, 0.587, 0.114])\n",
    "img = cv2.resize(img, dsize=(28, 28), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "img.resize((1, 1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert image into a NumPy array of type float32\n",
    "data = json.dumps({'data': img.tolist()})\n",
    "data = np.array(json.loads(data)['data']).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Name:  Input3\n",
      "Output Name:  Plus214_Output_0\n"
     ]
    }
   ],
   "source": [
    "# Pass the data to model for inference\n",
    "data = json.dumps({'data': img.tolist()})\n",
    "data = np.array(json.loads(data)['data']).astype('float32')\n",
    "session = onnxruntime.InferenceSession(model, None)\n",
    "input_name = session.get_inputs()[0].name\n",
    "output_name = session.get_outputs()[0].name\n",
    "\n",
    "print(\"Input Name: \", input_name)\n",
    "print(\"Output Name: \", output_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print prediction from infered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Value  2\n"
     ]
    }
   ],
   "source": [
    "# Pass input to session and print the prediction\n",
    "result = session.run([output_name], {input_name: data})\n",
    "prediction=int(np.argmax(np.array(result).squeeze(), axis=0))\n",
    "print(\"Predicted Value \", prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
